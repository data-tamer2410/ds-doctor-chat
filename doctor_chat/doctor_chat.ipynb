{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data-tamer2410/ds-doctor-chat/blob/master/doctor_chat/doctor_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task"
      ],
      "metadata": {
        "id": "gBoRwGRzVfUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Develop a chatbot that provides advice and recommendations on medical issues."
      ],
      "metadata": {
        "id": "HzNsP53rVink"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solution to the problem"
      ],
      "metadata": {
        "id": "kRJ-_JeDVlWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sx6OcFVvYrfl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, TFAutoModelForCausalLM, DataCollatorForSeq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = pd.read_csv('train.csv')\n",
        "test_dataset = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "axRmw0XlxY6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.isna().any())\n",
        "print(test_dataset.isna().any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-X7U_djxuW-",
        "outputId": "619515ac-d3bb-48bb-a87b-52e34bb7ac72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conversation    False\n",
            "dtype: bool\n",
            "Conversation    False\n",
            "dtype: bool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.duplicated().any())\n",
        "print(test_dataset.duplicated().any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myIBl0q6yTyH",
        "outputId": "93d51c88-d298-4ebc-dfff-e38eb187e1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before each token of a new reply, we will add \"\\n\" (if it's not already there).\n",
        "train_dataset = train_dataset['Conversation'].str.replace(r'(?<!\\n)(\\[\\|Human\\|\\]|\\[\\|AI\\|\\])', r'\\n\\1', regex=True)\n",
        "test_dataset = test_dataset['Conversation'].str.replace(r'(?<!\\n)(\\[\\|Human\\|\\]|\\[?\\|AI\\|\\])', r'\\n\\1', regex=True)"
      ],
      "metadata": {
        "id": "4hjW2m22BV9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.str.startswith(\"The conversation between human and AI assistant.\\n[|Human|] \").all())\n",
        "print(test_dataset.str.startswith(\"The conversation between human and AI assistant.\\n[|Human|] \").all())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRcDx4OFyhZJ",
        "outputId": "dd2faea7-0070-4840-c2cb-478a0a814fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's remove the unnecessary characters.\n",
        "start_text = \"The conversation between human and AI assistant.\\n\"\n",
        "train_dataset = train_dataset.str.replace(start_text,'')\n",
        "test_dataset = test_dataset.str.replace(start_text,'')\n",
        "\n",
        "train_dataset = train_dataset.str.replace(r'[“”\"‘’]', '', regex=True)\n",
        "test_dataset = test_dataset.str.replace(r'[“”\"‘’]', '', regex=True)"
      ],
      "metadata": {
        "id": "RqrdCBqi428z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The message type in the file consists of text messages containing detailed statements from dialogue participants. The main features:\n",
        "\n",
        "1. **Formatted Dialogue:** Each message begins with a marker indicating the speaker ([|Human|] or [|AI|]), which allows for role identification.\n",
        "\n",
        "2. **Content of Messages:**\n",
        "   - Messages from the patient (\"Human\") contain descriptions of symptoms, complaints, or questions.\n",
        "   - Messages from the doctor (\"AI\") contain detailed responses, possible diagnoses, or recommendations.\n",
        "\n",
        "3. **Message Separation:** Replies are separated by a newline character (\\n), but multiple messages can be on the same line in the file."
      ],
      "metadata": {
        "id": "BUSrKyfi1NEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the GPT-2 tokenizer.\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "6lKtGV8YdUea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding special tokens.\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "special_tokens = {'additional_special_tokens': ['[|Human|]', '[|AI|]']}\n",
        "tokenizer.add_special_tokens(special_tokens)"
      ],
      "metadata": {
        "id": "mYVaN3uJD863"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text tokenization.\n",
        "train_dataset = tokenizer(train_dataset.to_list(),truncation=True)\n",
        "test_dataset = tokenizer(test_dataset.to_list(),truncation=True)"
      ],
      "metadata": {
        "id": "mlMH8bdSFZkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing datasets.\n",
        "train_labels = [el[1:] + [tokenizer.eos_token_id] for el in train_dataset['input_ids']]\n",
        "test_labels = [el[1:] + [tokenizer.eos_token_id] for el in test_dataset['input_ids']]\n",
        "\n",
        "train_dataset['labels'] = train_labels\n",
        "test_dataset['labels'] = test_labels\n",
        "\n",
        "train_dataset = Dataset.from_dict(train_dataset)\n",
        "test_dataset = Dataset.from_dict(test_dataset)"
      ],
      "metadata": {
        "id": "qqjuI1aIH53L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, padding=True, return_tensors='tf',label_pad_token_id=tokenizer.eos_token_id)"
      ],
      "metadata": {
        "id": "WTEyUG_UPhlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "\n",
        "train_dataset = train_dataset.to_tf_dataset(\n",
        "    columns=['input_ids', 'attention_mask', 'labels'],\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "\n",
        "test_dataset = test_dataset.to_tf_dataset(\n",
        "    columns=['input_ids', 'attention_mask', 'labels'],\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "yCYEr7TlPr-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model.\n",
        "model = TFAutoModelForCausalLM.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "EkWLXq_dVVup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the size of the model's embedding matrices to account for the new tokens.\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "QjVXUDaqiGoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Gb990LVUu2J6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35bb30b-b401-4bc9-ac1e-7258af334001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tfgpt2lm_head_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " transformer (TFGPT2MainLay  multiple                  124441344 \n",
            " er)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124441344 (474.71 MB)\n",
            "Trainable params: 124441344 (474.71 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perplexity(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name=\"perplexity\", **kwargs):\n",
        "        super(Perplexity, self).__init__(name=name, **kwargs)\n",
        "        self.total_loss = self.add_weight(name=\"total_loss\", initializer=\"zeros\")\n",
        "        self.total_count = self.add_weight(name=\"total_count\", initializer=\"zeros\")\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # Calculating the loss (SparseCategoricalCrossentropy).\n",
        "        loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.SUM)\n",
        "        loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "        # Updating the total loss and token count.\n",
        "        self.total_loss.assign_add(loss)\n",
        "        self.total_count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "\n",
        "    def result(self):\n",
        "        # Calculating the average loss.\n",
        "        avg_loss = self.total_loss / self.total_count\n",
        "        # Perplexity: exp(average_loss).\n",
        "        return tf.exp(avg_loss)\n",
        "\n",
        "    def reset_state(self):\n",
        "        # Clearing the accumulators.\n",
        "        self.total_loss.assign(0.0)\n",
        "        self.total_count.assign(0.0)"
      ],
      "metadata": {
        "id": "7LOBg05J0Q9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model.\n",
        "epochs = 3\n",
        "lr = tf.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.00003,decay_steps=5000,decay_rate=0.96,staircase=True)\n",
        "optimizer = tf.optimizers.AdamW(learning_rate=lr)\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=[\"accuracy\",Perplexity()]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "Smds4Aq6u_ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('drive/MyDrive/gpt2-doctor-chat')\n",
        "tokenizer.save_pretrained('drive/MyDrive/gpt2-doctor-chat')"
      ],
      "metadata": {
        "id": "wXn9gF3c5JvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.evaluate(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCpWyKRKasvW",
        "outputId": "a43920e4-3231-4975-ecf5-6a53e9219306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2805/2805 [==============================] - 309s 109ms/step - loss: 2.6079 - accuracy: 0.5337 - perplexity: 12.9094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's test the model's performance.\n",
        "text = \"[|Human|] I've been experiencing persistent dizziness and nausea for the past two weeks, especially in the mornings. I also have occasional headaches and a feeling of pressure behind my eyes. Could this be related to a neurological issue or an inner ear disorder? What tests would you recommend to determine the cause, and what treatment options are available?\\n[|AI|]\"\n",
        "tokenize_text = tokenizer(text,return_tensors='tf')"
      ],
      "metadata": {
        "id": "hvxV0rmMuhJM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_generate = model.generate(**tokenize_text,\n",
        "                              max_length=500,eos_token_id=[\n",
        "                                  tokenizer.eos_token_id,\n",
        "                                  tokenizer.additional_special_tokens_id[1]\n",
        "                                  ],\n",
        "                              do_sample=True,\n",
        "                              top_p=0.9,\n",
        "                              repetition_penalty=1.2)"
      ],
      "metadata": {
        "id": "wjKUUfETxWGD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(res_generate[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "LuaA6Gw71yxB",
        "outputId": "276185e8-525a-46d4-c34c-2296034c3f0f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[|Human|] I've been experiencing persistent dizziness and nausea for the past two weeks, especially in the mornings. I also have occasional headaches and a feeling of pressure behind my eyes. Could this be related to a neurological issue or an inner ear disorder? What tests would you recommend to determine the cause, and what treatment options are available?\\n[|AI|]  Hi, Thankyou for posting your query. I agree with you that your symptoms are likely due to neurological disorders. The treatment options would range from a neurologic examination (carotid Doppler) to some imaging (imaging of brain), which can mimic any neurological disorder. You should get back if you require any additional information. Best wishes, Chat Doctor. Ly/\\n<|endoftext|>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "zKo8OuTiWe2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The developed chatbot for medical consultations is based on a fine-tuned GPT-2 model, adapted to recognize and generate dialogues between users and a virtual doctor.  \n",
        "\n",
        "### Testing results:  \n",
        "- **Perplexity**: 12.9094  \n",
        "- **Loss**: 2.6079  \n",
        "\n",
        "These metrics indicate the model's ability to effectively understand and generate medical responses with a relatively low level of uncertainty.  \n",
        "\n",
        "### Key features of the implementation:  \n",
        "- Use of special tokens (`[|Human|]` and `[|AI|]`) to structure dialogues correctly.  \n",
        "- Data cleaning and preprocessing to ensure accurate training.  \n",
        "- Adaptation of the GPT-2 model by adding new tokens and expanding the vocabulary.  \n",
        "- Application of the **Perplexity** metric to assess the model's ability to predict the next word in a sequence.  \n",
        "- Training optimization using `AdamW` and an exponential learning rate decay strategy.  \n",
        "\n",
        "Testing on real user queries demonstrated that the model can generate logical responses, provide possible diagnoses, and recommend medical examinations. Future improvements may include:  \n",
        "- Expanding the dataset with more specialized medical texts to enhance response accuracy.  \n",
        "- Utilizing more advanced language models (e.g., GPT-4).  \n",
        "- Integrating external medical knowledge bases.  \n",
        "\n",
        "The results highlight the potential of this approach for developing intelligent assistants in the healthcare sector."
      ],
      "metadata": {
        "id": "ckOe47nZWiaX"
      }
    }
  ]
}